{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grupppo 2: Operazioni di random sampling, serializzazione, operazioni pointwise, operazioni di riduzione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation and operations"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "~~~~~~~~~~~~~~~~~~~~~~\n",
    ".. autofunction:: eye\n",
    ".. autofunction:: from_numpy\n",
    ".. autofunction:: linspace\n",
    ".. autofunction:: logspace          \n",
    ".. autofunction:: ones\n",
    ".. autofunction:: ones_like\n",
    ".. autofunction:: arange\n",
    ".. autofunction:: range                   \n",
    ".. autofunction:: zeros\n",
    ".. autofunction:: zeros_like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.3733e-14, 6.4069e+02, 4.3066e+21],\n",
      "        [1.1824e+22, 4.3066e+21, 6.3828e+28]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x = torch.Tensor(2, 3)    # Create an un-initialized Tensor of size 2x3\n",
    "print(x)                  # Print out the Tensor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = torch.Tensor(2, 3)  # An un-initialized Tensor object. x holds garbage data.\n",
    "y = torch.rand(2, 3)    # Initialize with random values\n",
    "\n",
    "\n",
    "\n",
    "            # [torch.FloatTensor of size 2x3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v1\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "v2\n",
      "tensor([[[[1.],\n",
      "          [1.]]],\n",
      "\n",
      "\n",
      "        [[[1.],\n",
      "          [1.]]]])\n",
      "v3\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "v4\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "eye = torch.eye(3)              # Create an identity 3x3 tensor\n",
    "\n",
    "v1 = torch.ones(10)              # A tensor of size 10 containing all ones\n",
    "print('v1')\n",
    "print(v1)\n",
    "\n",
    "v2 = torch.ones(2, 1, 2, 1)      # Size 2x1x2x1....\n",
    "\n",
    "print('v2')\n",
    "print(v2)\n",
    "\n",
    "v3 = torch.ones_like(eye)        # A tensor with same shape as eye. Fill it with 1.\n",
    "print('v3')\n",
    "print(v3)\n",
    "\n",
    "v4 = torch.zeros(10)             # A tensor of size 10 containing all zeros\n",
    "print('v4')\n",
    "print(v4)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = torch.arange(5)             # similar to range(5) but creating a Tensor\n",
    "v = torch.arange(0, 5, step=1)  # Size 5. Similar to range(0, 5, 1)\n",
    "\n",
    "\n",
    "\n",
    "v0 = torch.linspace(1, 10, steps=10) # Create a Tensor with 10 linear points for (1, 10) inclusively\n",
    "\n",
    "v1 = torch.logspace(start=-10, end=10, steps=5) # Size 5: 1.0e-10 1.0e-05 1.0e+00, 1.0e+05, 1.0e+10\n",
    "\n",
    "v2 = torch.Tensor(2, 3)          # An un-initialized torch.FloatTensor of size 2x3\n",
    "\n",
    "v3 = torch.Tensor([[1,2],[4,5]]) # A Tensor initialized with a specific array\n",
    "\n",
    "v4 = torch.LongTensor([1,2,3])   # A Tensor of type Long\n",
    "\n",
    "\n",
    "\n",
    "c = torch.ByteTensor([0, 1, 1, 0]) #bytetensor\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important to remember that the type of a tensor is very important because they have different attributes and so  you cannot make operation among them straightforwardly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.is_tensor(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in Place operations end with “_” is in place operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.2251e-01, -8.5899e+09, -6.0648e+02],\n",
       "        [ 3.1349e-01,         nan,         nan]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.add_(y)        # Same as x = x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [2., 2., 2.],\n",
      "        [3., 3., 3.]])\n"
     ]
    }
   ],
   "source": [
    "v = torch.ones(3, 3)\n",
    "v[1].fill_(2)\n",
    "v[2].fill_(3)\n",
    "\n",
    "#will generate\n",
    "# 1  1  1\n",
    "# 2  2  2\n",
    "# 3  3  3\n",
    "\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "torch.Size([6])\n",
      "torch.Size([3, 2])\n",
      "torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "### Tensor resizing\n",
    "x = torch.randn(2, 3)            # Size 2x3\n",
    "y = x.view(6)                    # Resize x to size 6\n",
    "z = x.view(-1, 2)                # Size 3x2\n",
    "\n",
    "v = torch.ones(9)\n",
    "v = v.view(3, 3)                 #Size 3,3\n",
    "\n",
    "\n",
    "print(x.size())      # tensor.size like np.shape \n",
    "print(y.size())\n",
    "print(z.size())\n",
    "print(v.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = v.view(-1,3) # -1 matches the other dimension, it gives you error if is not possible to match like v.view(-1,2)\n",
    "                # indeed, v has 9 elements and it can just be reshaped in 3,3 \n",
    "print(v)    \n",
    "\n",
    "v2 = torch.ones(16)\n",
    "v2.view(2,2,-1)         # reshape a 1d tensor to a 3d tensor of 2 element per plane (2planes) where \n",
    "                        #you need to have (the -1 dim) 4 elements to match the size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this two are equal\n",
    "\n",
    "x.size()\n",
    "torch.numel(x)        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic Operations among tensors, the logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7576, 1.1091, 2.3059, 3.1591, 4.8885, 5.6264, 6.6783, 7.7181, 8.3030])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Operations\n",
    "x = torch.arange(9).float()\n",
    "\n",
    "y = torch.rand(9)\n",
    "\n",
    "z1 = x + y\n",
    "z2 = torch.add(x, y)             # Same as above\n",
    "\n",
    "print(z2)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = torch.Tensor(2, 3) #random inizialization\n",
    "\n",
    "r2 = torch.add(x, y, out=r1)   # defines r2 and also rewrite r1\n",
    "\n",
    "r3 = torch.add(x, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7576, 1.1091, 2.3059, 3.1591, 4.8885, 5.6264, 6.6783, 7.7181, 8.3030])\n",
      "tensor([0.7576, 1.1091, 2.3059, 3.1591, 4.8885, 5.6264, 6.6783, 7.7181, 8.3030])\n",
      "tensor([0.7576, 1.1091, 2.3059, 3.1591, 4.8885, 5.6264, 6.6783, 7.7181, 8.3030])\n"
     ]
    }
   ],
   "source": [
    "print(r2)\n",
    "print(r3)\n",
    "print(r1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy connection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 4., 7.])\n",
      "tensor([0., 3., 6.])\n",
      "tensor([0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "x= x.view(3,-1)\n",
    "\n",
    "print(x[:, 1])                      # Can use numpy type indexing\n",
    "print(x[:,0])\n",
    "\n",
    "x[:, 0] = 0                      # For assignment\n",
    "print(x[:,0])\n",
    "\n",
    "\n",
    "\n",
    "# like in numpy\n",
    "x1 =np.zeros(4)\n",
    "x2=x1.reshape(2,2)\n",
    "x2[:,1]=0\n",
    "\n",
    "#reshape works also for tensor and is similar to view x.reshape(3,3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Tensors"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Random sampling\n",
    "----------------------------------\n",
    ".. autofunction:: manual_seed    - Set a manual seed\n",
    ".. autofunction:: initial_seed   - Randomize a seed by the system\n",
    ".. autofunction:: get_rng_state\n",
    ".. autofunction:: set_rng_state\n",
    ".. autodata:: default_generator\n",
    ".. autofunction:: bernoulli\n",
    ".. autofunction:: multinomial\n",
    ".. autofunction:: normal\n",
    ".. autofunction:: rand\n",
    ".. autofunction:: randn\n",
    ".. autofunction:: randperm\n",
    "\n",
    "In-place random sampling\n",
    "~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "There are a few more in-place random sampling functions defined on Tensors as well. Click through to refer to their documentation:\n",
    "\n",
    "- :func:`torch.Tensor.bernoulli_` - in-place version of :func:`torch.bernoulli`\n",
    "- :func:`torch.Tensor.cauchy_` - numbers drawn from the Cauchy distribution\n",
    "- :func:`torch.Tensor.exponential_` - numbers drawn from the exponential distribution\n",
    "- :func:`torch.Tensor.geometric_` - elements drawn from the geometric distribution\n",
    "- :func:`torch.Tensor.log_normal_` - samples from the log-normal distribution\n",
    "- :func:`torch.Tensor.normal_` - in-place version of :func:`torch.normal`\n",
    "- :func:`torch.Tensor.random_` - numbers sampled from the discrete uniform distribution\n",
    "- :func:`torch.Tensor.uniform_` - numbers sampled from the continuous uniform distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x113191e90>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(5, 3).type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 3, 3, 3])\n",
      "tensor([ 1.2673,  2.2930,  2.6167,  4.9653,  6.5171,  6.2054,  6.6048,  7.7276,\n",
      "         9.1085, 10.0110])\n"
     ]
    }
   ],
   "source": [
    "# 2x2: A uniform distributed random matrix with range [0, 1]\n",
    "r = torch.Tensor(2, 2).uniform_(0, 1)\n",
    "\n",
    "# bernoulli\n",
    "r = torch.bernoulli(r)   # Size: 2x2. Bernoulli with probability p stored in elements of r\n",
    "\n",
    "# Multinomial\n",
    "w = torch.Tensor([0, 4, 8, 2]) # Create a tensor of weights\n",
    "r = torch.multinomial(w, 4, replacement=True) # Size 4: 3, 2, 1, 2\n",
    "\n",
    "print(r)\n",
    "\n",
    "# Normal distribution\n",
    "# From 10 means and SD\n",
    "r = torch.normal(mean=torch.arange(1., 11.), std=torch.arange(1, 0, -0.1))\n",
    "\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one single element tensor as to be specified with or mean or std a Float tensor of single element \n",
    "r0 =torch.normal(mean=2, std=torch.tensor([2]).float()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenation opearitions"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Indexing, Slicing, Joining, Mutating Ops\n",
    "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    ".. autofunction:: cat\n",
    ".. autofunction:: chunk             \n",
    ".. autofunction:: gather\n",
    ".. autofunction:: index_select\n",
    ".. autofunction:: masked_select\n",
    ".. autofunction:: nonzero\n",
    ".. autofunction:: split            \n",
    ".. autofunction:: squeeze\n",
    ".. autofunction:: stack\n",
    ".. autofunction:: t              - Transpose a 2-D tensor\n",
    ".. autofunction:: take\n",
    ".. autofunction:: transpose\n",
    ".. autofunction:: unbind         - Removes a tensor dimension\n",
    ".. autofunction:: unsqueeze\n",
    ".. autofunction:: where          - Select x or y Tensor elements based on condition Tensor c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2., -2., -2.],\n",
      "        [ 0.,  1.,  0.],\n",
      "        [ 3.,  3.,  3.],\n",
      "        [-2., -2., -2.],\n",
      "        [ 0.,  1.,  0.],\n",
      "        [ 3.,  3.,  3.],\n",
      "        [-2., -2., -2.],\n",
      "        [ 0.,  1.,  0.],\n",
      "        [ 3.,  3.,  3.]])\n",
      "tensor([[-2., -2., -2., -2., -2., -2., -2., -2., -2.],\n",
      "        [ 0.,  1.,  0.,  0.,  1.,  0.,  0.,  1.,  0.],\n",
      "        [ 3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.]])\n",
      "tensor([[[ 1.,  1.,  1.],\n",
      "         [-2., -2.,  1.],\n",
      "         [ 1.,  1.,  1.]],\n",
      "\n",
      "        [[ 1.,  1.,  1.],\n",
      "         [-2., -2.,  1.],\n",
      "         [ 1.,  1.,  1.]]])\n",
      "tensor([[ 1.,  1.,  1.],\n",
      "        [-2., -2.,  1.],\n",
      "        [ 1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.],\n",
      "        [-2., -2.,  1.],\n",
      "        [ 1.,  1.,  1.]])\n"
     ]
    }
   ],
   "source": [
    "# Concatenation\n",
    "\n",
    "x= torch.zeros(3,3)\n",
    "x[:,1] =1\n",
    "x[0].fill_(-2)\n",
    "x[2].fill_(3)\n",
    "\n",
    "\n",
    "v= torch.ones(3,3)\n",
    "v[1,:2].fill_(-2)\n",
    "\n",
    "r0=torch.cat((x, x, x),0)          # Concatenate in the 0 dimension ~ one over the other\n",
    "r0b= torch.cat((x, x, x),1)        # Concatenate in the 1 dimension ~one next to the other\n",
    "\n",
    "# Stack IS NOT cat because it stack with a new dimension the new tensor, do not merge the tensors like cat\n",
    "r1 = torch.stack((v, v))\n",
    "r1b= torch.cat((v,v),0)        \n",
    "\n",
    "print(r0)\n",
    "print(r0b)\n",
    "print(r1)\n",
    "print(r1b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather element\n",
    "# torch.gather(input, dim, index, out=None)\n",
    "# out[i][j][k] = input[index[i][j][k]][j][k]  # if dim == 0\n",
    "# out[i][j][k] = input[i][index[i][j][k]][k]  # if dim == 1\n",
    "# out[i][j][k] = input[i][j][index[i][j][k]]  # if dim == 2\n",
    "\n",
    "# 0  1\n",
    "# 4  3\n",
    "# 8  7\n",
    "\n",
    "v = torch.arange(9)\n",
    "v = v.view(3, 3)\n",
    "\n",
    "r = torch.gather(v, 1, torch.LongTensor([[0,1],[1,0],[2,1]]))\n",
    "\n",
    "\n",
    "# gather gives you a new tensor with the element of the input tensor at the index of the index_tensor , \n",
    "#taken in the direction of dim --> 1 normal direction ,-1 in the backward direction\n",
    "# I see the -1 dimension as if you look the  tensor from behind, so for nxn tensor \n",
    "#is like looking at the tensor on te other direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3])\n",
      "torch.Size([3, 2])\n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]])\n",
      "tensor([[0, 1],\n",
      "        [4, 3],\n",
      "        [8, 7]])\n"
     ]
    }
   ],
   "source": [
    "print(v.size())\n",
    "print(r.size())\n",
    "print(v)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split and chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split an array into 3 chunks\n",
    "# (\n",
    "# 0  1  2\n",
    "# [torch.FloatTensor of size 1x3]\n",
    "# ,\n",
    "# 3  4  5\n",
    "# [torch.FloatTensor of size 1x3]\n",
    "# ,\n",
    "# 6  7  8\n",
    "# [torch.FloatTensor of size 1x3]\n",
    "# )\n",
    "r0 = torch.chunk(v, 3)  #basically take the tensor and creates three \n",
    "                        #tensors from it adjusting the dimension to be the same\n",
    "\n",
    "# Split an array into chunks of at most size 2\n",
    "# (\n",
    "# 0  1  2\n",
    "# 3  4  5\n",
    "# [torch.FloatTensor of size 2x3]\n",
    "# ,\n",
    "# 6  7  8\n",
    "# [torch.FloatTensor of size 1x3]\n",
    "# )\n",
    "\n",
    "r0b = torch.split(v, 1)  #at most size 1 it means torch.chunk(v, 3)\n",
    "\n",
    "r1 = torch.split(v, 2)   # at most size 2 : one of 2 one of 1 dim ... it means torch.chunk(v, 2)\n",
    "r2 = torch.split(v,3)   # at most size 3 one of 3 one of 0 <-check it out this zero! it means torch.chunk(v,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[0, 1, 2]]), tensor([[3, 4, 5]]), tensor([[6, 7, 8]]))\n",
      "(tensor([[0, 1, 2]]), tensor([[3, 4, 5]]), tensor([[6, 7, 8]]))\n",
      "(tensor([[0, 1, 2],\n",
      "        [3, 4, 5]]), tensor([[6, 7, 8]]))\n",
      "(tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]]),)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "print(r0)\n",
    "print(r0b)\n",
    "print(r1)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "summarizing:\n",
    "\n",
    "torch.chunk(v,n) = torch.split(v, maxDimension-n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index select\n",
    "v = torch.arange(9)\n",
    "v = v.view(3, 3)\n",
    "# 0 2\n",
    "# 3 5\n",
    "# 6 8\n",
    "indices = torch.LongTensor([0, 2])\n",
    "ri = torch.index_select(v, 1, indices) # Select element 0 and 2 for each dimension 1.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Masked select\n",
    "# 0  0  0\n",
    "# 1  1  1\n",
    "# 1  1  1\n",
    "\n",
    "\n",
    "mask = v.ge(3)  #<- put zero in the element where you are smaller than 3 and 1 if you are equal or biigger\n",
    "                # can be used also for comparing tensors\n",
    "m2= torch.ge(torch.tensor([2,5]), torch.tensor([2,2]))\n",
    "\n",
    "# Size 6: 3 4 5 6 7 8\n",
    "rm = torch.masked_select(v, mask)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1]], dtype=torch.uint8)\n",
      "tensor([1, 1], dtype=torch.uint8)\n",
      "tensor([[0, 2],\n",
      "        [3, 5],\n",
      "        [6, 8]])\n",
      "tensor([3, 4, 5, 6, 7, 8])\n"
     ]
    }
   ],
   "source": [
    "print(mask)\n",
    "print(m2)\n",
    "print(ri)\n",
    "print(rm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.ones(2,1,2,1) # Size 2x1x2x1\n",
    "r0 = torch.squeeze(t)     # Size 2x2\n",
    "r1 = torch.squeeze(t, 1)  # Squeeze dimension 1: Size 2x2x1\n",
    "\n",
    "# Un-squeeze a dimension\n",
    "x = torch.Tensor([1, 2, 3])\n",
    "r2 = torch.unsqueeze(x, 0)       # Size: 1x3\n",
    "r3 = torch.unsqueeze(x, 1)       # Size: 3x1\n",
    "r4 = torch.unsqueeze(x, -1)       # Size: 3x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "tensor([[[1.],\n",
      "         [1.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.]]])\n",
      "tensor([[1., 2., 3.]])\n",
      "tensor([[1.],\n",
      "        [2.],\n",
      "        [3.]])\n",
      "tensor([[1.],\n",
      "        [2.],\n",
      "        [3.]])\n"
     ]
    }
   ],
   "source": [
    "print(r0)\n",
    "print(r1)\n",
    "print(r2)\n",
    "print(r3)\n",
    "print(r4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1],\n",
      "        [0, 2],\n",
      "        [1, 0],\n",
      "        [1, 1],\n",
      "        [1, 2],\n",
      "        [2, 0],\n",
      "        [2, 1],\n",
      "        [2, 2]])\n"
     ]
    }
   ],
   "source": [
    "# Non-zero\n",
    "# [torch.LongTensor of size 8x2]\n",
    "# [i, j] index for non-zero elements\n",
    "#    0     1\n",
    "#    0     2\n",
    "#    1     0\n",
    "#    1     1\n",
    "#    1     2\n",
    "#    2     0\n",
    "#    2     1\n",
    "#    2     2\n",
    "r = torch.nonzero(v)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 4, 3])\n",
      "tensor([[1, 1, 7],\n",
      "        [3, 7, 5],\n",
      "        [6, 6, 6]], dtype=torch.int32)\n",
      "tensor([1, 7, 3], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# Flatten a TensorFlow and return elements with given indexes\n",
    "# Size 3: 0, 4, 2\n",
    "v= torch.arange(9)\n",
    "r = torch.take(v, torch.LongTensor([0, 4, 3]))\n",
    "print(r)\n",
    "\n",
    "\n",
    "v=(10*torch.rand(3,3)).int()\n",
    "r1 = torch.take(v, torch.LongTensor([0, 4, 3]))\n",
    "print(v)\n",
    "print(r1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 3, 6],\n",
      "        [1, 4, 7],\n",
      "        [2, 5, 8]])\n",
      "torch.Size([3, 3, 3])\n",
      "tensor([[[ 0,  1,  2],\n",
      "         [ 9, 10, 11],\n",
      "         [18, 19, 20]],\n",
      "\n",
      "        [[ 3,  4,  5],\n",
      "         [12, 13, 14],\n",
      "         [21, 22, 23]],\n",
      "\n",
      "        [[ 6,  7,  8],\n",
      "         [15, 16, 17],\n",
      "         [24, 25, 26]]])\n"
     ]
    }
   ],
   "source": [
    "# Transpose dim 0 and 1\n",
    "v=torch.arange(9).view(3,3)\n",
    "r1 = torch.transpose(v,0,1)\n",
    "print(r1)\n",
    "\n",
    "v=torch.arange(27)\n",
    "v=v.reshape(3,3,-1)\n",
    "print(v.size())\n",
    "\n",
    "r2 = torch.transpose(v,1,0)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pointwise operations"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Pointwise Ops\n",
    "~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    ".. autofunction:: abs\n",
    ".. autofunction:: acos           - arc cosine\n",
    ".. autofunction:: add\n",
    ".. autofunction:: addcdiv        - element wise: t1 + s * t2/t3\n",
    ".. autofunction:: addcmul        - element wise: t1 + s * t2 * t3\n",
    ".. autofunction:: asin           - arc sin\n",
    ".. autofunction:: atan\n",
    ".. autofunction:: atan2\n",
    ".. autofunction:: ceil           - ceiling\n",
    ".. autofunction:: clamp          - clamp elements into a range\n",
    ".. autofunction:: cos\n",
    ".. autofunction:: cosh\n",
    ".. autofunction:: div            - divide\n",
    ".. autofunction:: erf            - Gaussian error functiom\n",
    ".. autofunction:: erfinv         - Inverse\n",
    ".. autofunction:: exp\n",
    ".. autofunction:: expm1          - exponential of each element minus 1\n",
    ".. autofunction:: floor          \n",
    ".. autofunction:: fmod           - element wise remainder of division\n",
    ".. autofunction:: frac           - fraction part 3.4 -> 0.4\n",
    ".. autofunction:: lerp           - linear interpolation\n",
    ".. autofunction:: log            - natural log\n",
    ".. autofunction:: log1p          - y = log(1 + x)\n",
    ".. autofunction:: mul            - multiple\n",
    ".. autofunction:: neg \n",
    ".. autofunction:: pow\n",
    ".. autofunction:: reciprocal     - 1/x\n",
    ".. autofunction:: remainder      - remainder of division\n",
    ".. autofunction:: round\n",
    ".. autofunction:: rsqrt          - the reciprocal of the square-root \n",
    ".. autofunction:: sigmoid        - sigmode(x)\n",
    ".. autofunction:: sign\n",
    ".. autofunction:: sin\n",
    ".. autofunction:: sinh\n",
    ".. autofunction:: sqrt\n",
    ".. autofunction:: tan\n",
    ".. autofunction:: tanh\n",
    ".. autofunction:: trunc          - truncated integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = torch.arange(9)\n",
    "v = v.view(3, 3)\n",
    "x = torch.randn(5, 3).type(torch.FloatTensor)\n",
    "y = torch.randn(5, 3).type(torch.FloatTensor)\n",
    "### Math operations\n",
    "f= torch.FloatTensor([-1, -2, 3])\n",
    "r = torch.abs(f)      # 1 2 3\n",
    "\n",
    "# Add x, y and scalar 10 to all elements\n",
    "r = torch.add(x, 10)\n",
    "r = torch.add(x, 10, y)\n",
    "\n",
    "# Clamp the value of a Tensor\n",
    "r = torch.clamp(v, min=-0.5, max=0.5)\n",
    "\n",
    "\n",
    "\n",
    "# Element-wise divide\n",
    "#r = torch.div(2*v, v) ##MY KERNEL DIES\n",
    "\n",
    "# Element-wise multiple\n",
    "r = torch.mul(v, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduction operations"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Reduction Ops\n",
    "~~~~~~~~~~~~~~~~~~~~~~\n",
    ".. autofunction:: cumprod        - accumulate product of elements x1*x2*x3...\n",
    ".. autofunction:: cumsum\n",
    ".. autofunction:: dist           - L-p norm\n",
    ".. autofunction:: mean\n",
    ".. autofunction:: median\n",
    ".. autofunction:: mode\n",
    ".. autofunction:: norm           - L-p norm\n",
    ".. autofunction:: prod           - accumulate product\n",
    ".. autofunction:: std            - compute standard deviation\n",
    ".. autofunction:: sum\n",
    ".. autofunction:: var            - variance of all elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  1.,  2.],\n",
      "        [ 3.,  5.,  7.],\n",
      "        [ 9., 12., 15.]])\n"
     ]
    }
   ],
   "source": [
    "### Reduction operations\n",
    "\n",
    "# Accumulate sum\n",
    "#  0   1   2\n",
    "#  3   5   7\n",
    "#  9  12  15\n",
    "\n",
    "v=v.float()\n",
    "\n",
    "r = torch.cumsum(v, dim=0)\n",
    "print(r)\n",
    "\n",
    "# L-P norm\n",
    "\n",
    "r = torch.dist(v, v+3, p=2)  # L-2 norm: ((3^2)*9)^(1/2) = 9.0\n",
    "\n",
    "# Mean\n",
    "# 1 4 7\n",
    "r = torch.mean(v, 1)         # Size 3: Mean in dim 1\n",
    "\n",
    "r = torch.mean(v, 1, True)   # Size 3x1 since keep dimension = True\n",
    "\n",
    "# Sum\n",
    "# 3 12 21\n",
    "r = torch.sum(v, 1)          # Sum over dim 1\n",
    "\n",
    "# 36\n",
    "r = torch.sum(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison Operations"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Comparison Ops\n",
    "~~~~~~~~~~~~~~~~~~~~~~\n",
    ".. autofunction:: eq             - Compare elements\n",
    ".. autofunction:: equal          - True of 2 tensors are the same \n",
    ".. autofunction:: ge             - Element-wise greater or equal comparison\n",
    ".. autofunction:: gt\n",
    ".. autofunction:: kthvalue       - k-th element\n",
    ".. autofunction:: le\n",
    ".. autofunction:: lt\n",
    ".. autofunction:: max\n",
    ".. autofunction:: min\n",
    ".. autofunction:: ne\n",
    ".. autofunction:: sort\n",
    ".. autofunction:: topk           - top k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-3.7931,  0.3771,  2.5407],\n",
      "        [-2.4214, -1.1351,  4.2099],\n",
      "        [ 1.1458,  5.9484,  5.5220]])\n",
      "tensor([[1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1]], dtype=torch.uint8)\n",
      "(tensor([2.5407, 4.2099, 5.9484]), tensor([2, 2, 1]))\n"
     ]
    }
   ],
   "source": [
    "# Size 3x3: Element-wise comparison\n",
    "v=4*torch.randn(9).view(3,-1)\n",
    "print(v)\n",
    "r = torch.eq(v, v)\n",
    "\n",
    "# Max element with corresponding index\n",
    "r1 = torch.max(v, 1)    # the ouptut are two tensors, one of the max along the dim 1 \n",
    "                        #and one of the indexes for the max location\n",
    "\n",
    "print(r)\n",
    "print(r1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
